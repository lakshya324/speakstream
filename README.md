# SpeakStream - Real-time Streaming Chatbot

A web-based chatbot that processes user input using a small, efficient language model and streams both text and audio responses in real-time.

## âœ¨ Version 1.1.0 - Stable Release

### ğŸ¯ Production Ready Features

- âœ… **Fully functional UI** - Send button, audio indicators, and chat history all working
- âœ… **Robust audio system** - Progressive playback with comprehensive debugging tools
- âœ… **Environment configuration** - Complete configuration via `.env` file
- âœ… **Persistent chat history** - Session restoration with localStorage
- âœ… **Comprehensive debugging** - Audio diagnostics and WebSocket testing tools

### ï¿½ï¸ Technical Improvements

- ğŸ“ **Configuration API** - `/config` endpoint for dynamic frontend configuration
- ğŸµ **Audio debugging** - Dedicated debug page at `/static/audio-debug.html`
- ğŸ”§ **Enhanced logging** - Detailed debugging throughout the audio pipeline
- ğŸŒ **WebSocket reliability** - Auto-reconnect and improved error handling
- ğŸ’¾ **Data persistence** - Configurable chat history limits and storage

## Features

- **Real-time Text Generation**: Uses HuggingFace SmolLM2-135M-Instruct for efficient text generation
- **Progressive Speech Synthesis**: Converts text chunks to audio using Coqui TTS (glow-tts model)
- **Streaming Audio Playback**: Streams audio to frontend for smooth, real-time playback
- **Asynchronous Backend**: FastAPI-based backend with WebSocket support
- **Web Audio API**: Low-latency audio playback in the browser
- **Environment Configuration**: All settings configurable via `.env` file
- **Chat History**: Persistent conversation history with localStorage

## Architecture

```text
Frontend (Web Browser)
â”œâ”€â”€ HTML5 + JavaScript + CSS
â”œâ”€â”€ Configuration loader (config.js)
â”œâ”€â”€ WebSocket connection with auto-reconnect
â”œâ”€â”€ Web Audio API with enhanced debugging
â”œâ”€â”€ Progressive audio buffer management
â””â”€â”€ Chat history persistence

Backend (FastAPI)
â”œâ”€â”€ Environment-based configuration
â”œâ”€â”€ WebSocket handler with improved streaming
â”œâ”€â”€ Text streaming with SmolLM2
â”œâ”€â”€ TTS chunking and synthesis
â”œâ”€â”€ Audio streaming optimization
â””â”€â”€ Configuration API endpoint
```

## Quick Start

1. **Install dependencies**:

   ```bash
   pip install -r requirements.txt
   ```

2. **Configure settings** (optional):

   Edit `.env` file:

   ```bash
   # Key settings
   PORT=8000
   DEFAULT_VOLUME=0.8
   SAVE_CHAT_HISTORY=true
   MAX_NEW_TOKENS=512
   ```

3. **Start the backend**:

   ```bash
   python backend/main.py
   ```

4. **Open the frontend**:

   Visit <http://localhost:8000> in your browser

5. **Start chatting**:

   - Click "Connect" to establish connection
   - Type a message and press Enter
   - Click anywhere first to enable audio!

## ğŸ”§ Configuration Options

All settings are now configurable via the `.env` file:

```bash
# Server Settings
HOST=0.0.0.0
PORT=8000
DEBUG=true

# Model Settings  
LLM_MODEL_NAME=HuggingFaceTB/SmolLM2-135M-Instruct
TTS_MODEL_NAME=tts_models/en/ljspeech/glow-tts
TTS_SAMPLE_RATE=22050

# Audio Settings
DEFAULT_VOLUME=0.8
ENABLE_AUDIO=true
CHUNK_SIZE=1024
MAX_QUEUE_SIZE=10

# UI Settings
AUTO_SCROLL=true
SAVE_CHAT_HISTORY=true
MAX_CHAT_HISTORY=100

# Generation Settings
MAX_NEW_TOKENS=512
TEMPERATURE=0.7
TOP_P=0.9
DO_SAMPLE=true
```

## Technical Details

### Text Generation Strategy

- Uses HuggingFace Transformers with `TextIteratorStreamer`
- Streams tokens in real-time to minimize latency
- Implements smart text chunking based on punctuation and length
- Environment-configurable generation parameters

### Audio Synthesis Pipeline

- Segments streaming text into coherent units for TTS
- Uses Coqui TTS glow-tts model for fast inference
- Converts WAV output to base64 for WebSocket transmission
- Implements audio buffer management for smooth playback
- Enhanced error handling and debugging

### Latency Optimization

- Asynchronous processing pipeline
- Streaming text generation
- Progressive TTS synthesis
- Audio buffer pre-loading
- WebSocket communication with auto-reconnect

### Configuration Management

- Centralized `.env` configuration
- Runtime config loading via `/config` endpoint
- Frontend adapts to backend settings
- No hardcoded values in client code

## Models Used

- **Language Model**: HuggingFaceTB/SmolLM2-135M-Instruct (135M parameters)
- **TTS Model**: tts_models/en/ljspeech/glow-tts
- **Memory Footprint**: ~400MB total

## Performance Characteristics

- **Text Generation**: ~50-100 tokens/second
- **TTS Latency**: ~200-500ms per chunk
- **Audio Buffer**: 2-3 seconds ahead
- **Total Response Time**: <1 second to first audio

## ğŸ› Troubleshooting

### Fixed in v1.1.0

- âœ… Send button always disabled â†’ Now works properly
- âœ… Audio indicator stuck â†’ Updates correctly  
- âœ… No chat history â†’ Persistent storage
- âœ… Hardcoded settings â†’ Environment config

### Common Issues

**No Audio**: Click anywhere on the page first to enable audio context

**Connection Issues**: Check if server is running on port 8000

**Debug Tools**:

- Visit `/static/audio-debug.html` for audio testing
- Check browser console (F12) for errors
- Run `python test_websocket.py` for backend testing

## Project Structure

```text
speakstream/
â”œâ”€â”€ ğŸ“„ README.md              # This file
â”œâ”€â”€ ğŸ“„ QUICKSTART.md          # Quick setup guide
â”œâ”€â”€ ğŸ“„ TECHNICAL_DOCS.md      # Detailed technical docs
â”œâ”€â”€ ğŸ“„ requirements.txt       # Python dependencies
â”œâ”€â”€ ğŸ“„ .env                   # Configuration file
â”œâ”€â”€ ğŸ“„ LICENSE                # MIT license
â”œâ”€â”€ ğŸ“„ test_websocket.py      # WebSocket test script
â”œâ”€â”€ 
â”œâ”€â”€ ğŸ—‚ï¸ backend/               # FastAPI server
â”‚   â”œâ”€â”€ ğŸ main.py            # Main app with config endpoint
â”‚   â”œâ”€â”€ ğŸ—‚ï¸ models/
â”‚   â”‚   â”œâ”€â”€ ğŸ llm_handler.py # SmolLM2 (.env configured)
â”‚   â”‚   â””â”€â”€ ğŸ tts_handler.py # Coqui TTS (.env configured)
â”‚   â”œâ”€â”€ ğŸ—‚ï¸ utils/
â”‚   â”‚   â”œâ”€â”€ ğŸ text_chunker.py # Text segmentation
â”‚   â”‚   â””â”€â”€ ğŸ audio_utils.py # Audio processing
â”‚   â””â”€â”€ ğŸ—‚ï¸ websocket/
â”‚       â””â”€â”€ ğŸ chat_handler.py # WebSocket (fixed streaming)
â”œâ”€â”€
â””â”€â”€ ğŸ—‚ï¸ frontend/              # Web interface
    â”œâ”€â”€ ğŸ“„ index.html         # Main page (config loading)
    â”œâ”€â”€ ğŸ“„ debug.html         # WebSocket debugging tool
    â”œâ”€â”€ ğŸ“„ audio-debug.html   # Audio debugging tool
    â”œâ”€â”€ ğŸ—‚ï¸ css/
    â”‚   â””â”€â”€ ğŸ“„ style.css      # Styling
    â””â”€â”€ ğŸ—‚ï¸ js/
        â”œâ”€â”€ ğŸ“„ config.js      # Configuration loader
        â”œâ”€â”€ ğŸ“„ audio-player.js # Web Audio API (enhanced)
        â”œâ”€â”€ ğŸ“„ websocket.js   # WebSocket client (config-aware)
        â”œâ”€â”€ ğŸ“„ ui-fixed.js    # UI controller (production)
        â””â”€â”€ ğŸ“„ ui.js          # UI controller (development)
```

## ğŸ“– Documentation

- **[QUICKSTART.md](QUICKSTART.md)** - 5-minute setup guide
- **[TECHNICAL_DOCS.md](TECHNICAL_DOCS.md)** - Detailed architecture docs
- **`.env`** - Configuration reference with comments

## ğŸ¯ Current Status

**Production Ready** âœ… - All core functionality is working:

- âœ… **Backend**: FastAPI server with WebSocket streaming and configuration API
- âœ… **Models**: SmolLM2-135M-Instruct for text + Coqui TTS for audio synthesis  
- âœ… **Frontend**: Full-featured web UI with audio playback and chat history
- âœ… **Configuration**: Complete `.env` file configuration system
- âœ… **Debugging**: Comprehensive debugging tools and error handling
- âœ… **Documentation**: Complete setup guides and technical documentation

## ğŸ¯ What's Next

- ğŸµ Multiple TTS voice options
- ğŸŒ Multi-language support  
- ğŸ’¾ Server-side chat persistence
- ğŸ”Š Real-time voice input
- ğŸ“± Mobile app version

---

**ğŸ‰ Enjoy real-time AI conversations with SpeakStream!**

Built with â¤ï¸ using open-source models and modern web technologies.
